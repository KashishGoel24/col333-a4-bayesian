1. Intiailize not using uniform values but read the input file once to intialize smartly (ignore question marks and then count) -
2. Improve the data structure / parser 
3. Our iterations are too slow ? why ? 
4. What if there are no question marks ? -> bug prone  
5. Also the places where the data point is low in number , just read that more times ? not everything else ,in which we are already very confident about the values ?
6. Read code from github 2 years ago ? 
7. Explore new ideas, read about how to train a bayesian network
8. Are some values given in the bif file that are fixed ? -> done 
9. Inference using random methods 


Possible improvement for iterations : 
1. update cpt is taking lot of time in which rewrite cpt is taking majority of the time 
2. can do something so that dont have to make value row again and again


to fix rewrite cpt: 
we can make vector norm an attribute of every node and when using the function update sum cpt, we can update the norm const at that position
we can initialise the norm const according to the initial values of sum cpt
